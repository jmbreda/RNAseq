#!/usr/bin/env python

###########################################################################
## Author: Gobet CÃ©dric
## Email: cedric.gobet@epfl.ch
## Date: 01/01/2023
##
## Pipeline to compute intron and exon counts from GTEX RNA-seq raw data
## library: un-stranded, polyA, paired-end 2x75bp
###########################################################################


import pandas as pd
import glob
import numpy as np
import os
import re
import json 

#### Load configuration and sample sheet ####
configfile: 'config.yaml'
workdir: config['workdir']

refdir = config['ref']
homedir = config['homedir']

spec = config['species']
GTF_URL = config[spec]['gtf']
GENOME_URL = config[spec]['genome']

#list of GTEX subject ID to analyze

df = pd.read_csv(os.path.join(homedir, config['samples']),sep='\t')

#### Load json from GTEX and subselect for subject IDs provided in the config file

data = json.load(open(os.path.join(homedir, config['js']),'r'))


pathi = os.path.join(homedir,"manifest")
if not os.path.exists(pathi):
   os.makedirs(pathi)

def create_manifest_ID(data, ID):
        for k in data:
            if((ID in k['file_name']) and not k['file_name'].endswith("bai") and 'H3K27ac' not in k['file_name']):
                fn = os.path.join(homedir + "manifest/file-manifest_") + k['file_name'].split('.')[0] + ".json"
                json.dump(k,open(fn,'w'), indent=4)
                with open(fn, "r") as file_object:
                    re=file_object.read()
                with open(fn, "w") as file_object:
                    file_object.write("[" + re + "]")


def return_all_bam(data, df):

    my_bam = []
    for v in df['ID']:
        for k in data:
            if((v in k['file_name']) and not k['file_name'].endswith("bai")):
                mb = k['file_name']
                size = len(mb)
                mod_mb = mb[:size - 4]
                my_bam.append(mod_mb)
                
    return my_bam   


all_bam = return_all_bam(data, df)
all_sample = [i.split('.')[0] for i in all_bam]

sample_bam = {all_sample[i]: all_bam[i] for i in range(len(all_bam))}
bam_sample = {all_bam[i]: all_sample[i] for i in range(len(all_bam))}


##--------------------------------------##
##  Target rule                         ##
##--------------------------------------##

rule all:
     input:
        expand('counting/{sample}/{sample}_ie.tsv', sample=all_sample)

##----------------------------------------------------------------##
## Generate json manifest file for the downloading                ##
##----------------------------------------------------------------##

rule createManifest:
    output:
        "{homedir}manifest/file-manifest_{sample}.json"
    params:
        samples_from_wc = lambda wc: wc.sample
    run:
        create_manifest_ID(data, params.samples_from_wc)      

##----------------------------------------------------------------##
## Download Bam files from GTEX database using gen3-client        ##
##----------------------------------------------------------------##

rule downloadBAM:
    input:
        lambda wildcards: os.path.join(homedir,'manifest/file-manifest_' + bam_sample[wildcards.BAM] + '.json')
    output:
        temp("raw/BAM/{BAM}.bam")
    shell:
        """

        {homedir}gen3-client download-multiple --profile=cgobet --manifest={input} â€“-skip-completed --download-path=raw/BAM --protocol=s3 --no-prompt

        """

##----------------##
## BAM to fastqs  ##
##----------------##

rule Bam2Fastq:
    input:
       lambda wildcards: "raw/BAM/" + sample_bam[wildcards.sample] + ".bam"
    output:
        r1 = temp("raw/FASTQ/{sample}_1.fastq.gz"),
        r2 = temp("raw/FASTQ/{sample}_2.fastq.gz")
    shell:
        """
        
        java -jar {homedir}picard.jar SamToFastq INPUT={input} FASTQ={output.r1} SECOND_END_FASTQ={output.r2}
        
        """
##--------------------------------------##
##  Download gtf from Ensembl           ##
##--------------------------------------##

rule download_ensembl_gtf:
    output: 
        gtf = os.path.join(refdir, spec, "ensembl.gtf")
    params: 
        url = GTF_URL
    shell: "wget -O {output.gtf}.gz {params.url}; gunzip {output.gtf}.gz"

##--------------------------------------##
##  Download dna from Ensembl           ##
##--------------------------------------##

rule download_ensembl_genome:
    output: 
        genome = os.path.join(refdir, spec, "ensembl.genome.fa")
    params: 
        url = GENOME_URL
    shell: "wget -O {output.genome}.gz {params.url}; gunzip {output.genome}.gz"

##--------------------------------------##
##  Make exon-intron annotation         ##
##--------------------------------------##

rule make_annot:
    input:
        gtf = os.path.join(refdir, spec, "ensembl.gtf")
	
    output:
        intron = os.path.join(refdir, spec, "ensembl.gtf.introns.final.bed"),
        exon =  os.path.join(refdir, spec, "ensembl.gtf.exons.final.bed")
    envmodules:
        "gcc/11.3.0",
        "bedtools2/2.30.0"

    shell: "bash {homedir}script/Make_annot.sh {input.gtf} {output.intron} {output.exon} "

##--------------------------------------##
##  Generate STAR genome index          ##
##--------------------------------------##

rule run_index_star:
    input: 
        fa = rules.download_ensembl_genome.output.genome,
        gtf = rules.download_ensembl_gtf.output.gtf
    output: genome = directory(refdir + spec + '/genome')
    envmodules:
        "gcc/11.3.0",
        "star/2.7.6a"
    shell: 
        "mkdir {output.genome}; STAR --runMode genomeGenerate --runThreadN 24 --genomeFastaFiles {input.fa} --sjdbGTFfile {input.gtf} --genomeDir {output.genome} --limitGenomeGenerateRAM 93035362005 --sjdbOverhang 75"

##--------------------------------------##
##  STAR alignment to the genome        ##
##--------------------------------------##

rule runstar:
    input:
        r1 = "raw/FASTQ/{sample}_1.fastq.gz",
        r2 = "raw/FASTQ/{sample}_2.fastq.gz",
        genome = rules.run_index_star.output.genome
    output:
        temp("mapping/{sample}/{sample}Aligned.sortedByCoord.out.bam")
    params: star_params = "--outSAMtype BAM SortedByCoordinate --limitBAMsortRAM 71000000000"
    envmodules:
        "gcc/11.3.0",
        "star/2.7.6a"
    shell:
        "STAR --genomeDir {input.genome} {params.star_params} --outFileNamePrefix mapping/{wildcards.sample}/{wildcards.sample} --readFilesIn {input.r1} {input.r2} --runThreadN 12 --readFilesCommand zcat"
      

##--------------------------------------##
##  BAM files indexing                  ##
##--------------------------------------##

rule samindex:
    input:
        "mapping/{sample}/{sample}Aligned.sortedByCoord.out.bam"
    output:
        temp("mapping/{sample}/{sample}Aligned.sortedByCoord.out.bam.bai")
    envmodules:
        "gcc/11.3.0",
        "samtools/1.14"
    shell: 
        "samtools index {input}"

##--------------------------------------##
##  Intron-exon counting                ##
##--------------------------------------##

rule countreads:
    input:
        bam = "mapping/{sample}/{sample}Aligned.sortedByCoord.out.bam", 
	    bam_index = "mapping/{sample}/{sample}Aligned.sortedByCoord.out.bam.bai",
        intron = rules.make_annot.output.intron,
        exon = rules.make_annot.output.exon,
    output:
        "counting/{sample}/{sample}_ie.tsv" 
    envmodules:
        "gcc/11.3.0",
        "samtools/1.14"
    shell: 
        "perl {homedir}script/Counting_IE_PairedEnd_unstranded.pl {input.intron} {input.exon} {input.bam} >  {output}"
      
