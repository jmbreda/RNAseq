# RNAseq processing pipeline

# Prior to running the pipeline, the following files need to be prepared:
# SraRunTable.txt
# SRR_Acc_List.txt
# GSMID_SampleName.txt
# -> SRR_per_SampleName.txt generated with workflow/Snakefile_download.smk

# slurm submission: 
# snakemake -s workflow/Snakefile -j 999 --cluster-config config/cluster.json --cluster "sbatch --job-name {cluster.name} --output {cluster.stdout} --error {cluster.stderr} --qos {cluster.qos} --time {cluster.time} --mem {cluster.mem} --nodes {cluster.nodes} --ntasks {cluster.ntasks} --cpus-per-task {cluster.cpus-per-task}"

import os
import pandas as pd

#configfile: "config/config.yaml"
#configfile: "config/Zhang_PNAS_2014.yml"
#configfile: "config/Atger_PNAS_2015.yml"
#configfile: "config/Weger_CellMetab_2019.yml"
#configfile: "config/astafev_2024.yml"
configfile: "config/mekbib_2022.yml"

def get_acc_list(dataset):
    infile = "resources/"+dataset+"/SRR_Acc_List.txt"
    with open(infile, 'r') as f:
        acc_list = f.read().splitlines()
    return acc_list

def get_sample_name(dataset):
    infile = "resources/"+dataset+"/SRR_per_SampleName.txt"
    with open(infile, 'r') as f:
        sample_name = [l.split('\t')[0] for l in f.read().splitlines()[1:]]
    return sample_name

def get_sample_WT_CTRL(dataset):
    sample_name = get_sample_name(dataset)

    # select only samples with circadian time and to treatment (CTRL)
    if dataset == 'Weger_CellMetab_2019':    
        sample_name = [s for s in sample_name if s[:3]=='CTR']
        
    # select only samples with circadian time and to treatment (WT_AL)
    if dataset == 'Atger_PNAS_2015':
        sample_name = [s for s in sample_name if s[:5]=='WT_AL']

    return sample_name

def get_srr_list(wildcards):
    infile = "resources/"+wildcards.dataset+"/SRR_per_SampleName.txt"
    df = pd.read_csv(infile, sep='\t',index_col=0)
    srr_list = df.at[wildcards.sample_name,'Run']
    
    return srr_list

rule all:
    input:
        # get data
        #expand("log/{dataset}/fasterq-dump/{sample}.out", dataset=config['Name'], sample=get_acc_list(config['Name'])),
        #expand("resources/{dataset}/fastq/{sample_name}_{r}.fastq.gz",dataset=config['Name'],sample_name=get_sample_name(config['Name']),r=['R1','R2']),
        # get genome annotation
        #expand("resources/genome/{spec}/{file}",spec=config['Species'],file=config['GenomeFiles']),
        #expand("resources/genome/{spec}/ensembl.gtf.{splicing}.final.bed",spec=config['Species'],splicing=['introns','exons','genes']),
        #expand("resources/genome/{spec}/transcripts.idx",spec=config['Species']),
        # map (jed)
        #expand("results/{dataset}/kallisto/{sample_name}/abundance.tsv", dataset=config['Name'], sample_name=get_sample_name(config['Name'])),
        #expand("results/{dataset}/kallisto/premrna_tpm_table.tab",dataset=config['Name']),
        #expand("results/{dataset}/kallisto/mrna_tpm_table.tab",dataset=config['Name']),
        expand("results/{dataset}/kallisto/promoter_premrna_table.tab",dataset=config['Name']),
        expand("results/{dataset}/kallisto/promoter_mrna_table.tab",dataset=config['Name']),
        #
        #expand("resources/genome/{spec}/star_index/", spec=config['SPECIES']),
        #expand("results/star/{sample_name}/Aligned.sortedByCoord.out.bam", sample_name=get_sample_name(config['Name']))
        #expand("results/star/{sample_name}/Aligned.sortedByCoord.out.bam.bai", sample_name=get_sample_name(config['Name']))
        #expand("results/counting/{sample_name}/ie_ol.tsv", sample_name=get_sample_name(config['Name']))
        #
        #expand("results/promoterome/{spec}/promid_transcripts.txt", spec=config['Species']),
        #expand("resources/{dataset}/file_list.txt",dataset=config['Name'])
        #expand("log/{dataset}/ismara/ismara_upload.out",dataset=config['Name'])



##-----------------------------------------------##
##   Concatenate SRR and rename by sample name   ##
##-----------------------------------------------##

rule concatenate_rename:
    input:
        infolder="resources/{dataset}/fastq",
    params:
        srr_list = lambda wildcards: get_srr_list(wildcards),
    output:
        fq1="resources/{dataset}/fastq/{sample_name}_R1.fastq.gz",
        fq2="resources/{dataset}/fastq/{sample_name}_R2.fastq.gz"
    shell:
        """
        python scripts/concatenate.py --SampleName {wildcards.sample_name} --srr_list {params.srr_list} --infolder {input.infolder} --fq1 {output.fq1} --fq2 {output.fq2}
        """

##-------------------------##
##   Upload to ismara      ##
##-------------------------##

rule make_file_list:
    input:
        expand("resources/{dataset}/fastq/{sample_name}_{paired_reads}.fastq.gz",dataset=config['Name'],sample_name=get_sample_WT_CTRL(config['Name']),paired_reads=['R1','R2'])
    output:
        file_list="resources/{dataset}/file_list.txt"
    shell:
        """
        ls {input} > {output.file_list}
        """

rule upload_ismara:
    input:
        file_list="resources/{dataset}/file_list.txt"
    output:
        stdout="log/{dataset}/ismara/ismara_upload.out"
    params:
        species=config['Species'],
        stderr="log/{dataset}/ismara/ismara_upload.err"
    shell:
        """
        python scripts/ismara_uploader.py -e jeremie.breda@epfl.ch -p {wildcards.dataset} -t rnaseq -o {params.species} --mirna --file-list {input.file_list} 1> {output.stdout} 2> {params.stderr}
        """


##---------------------------------------------------------------------------##
##   Download gtf, cDNA (coding transcripts), and DNA from Gencode/Ensembl   ##
##---------------------------------------------------------------------------##

rule download_ensembl_gtf:
    output: 
        "resources/genome/{spec}/gene_annotation.gtf"
    params: 
        url = lambda wildcards: config['URLs']['gtf']
    shell:
        """
        wget -O {output}.gz {params.url}
        gunzip {output}.gz
        """

rule download_ensembl_cdna:
    output: 
        "resources/genome/{spec}/cdna.fa"
    params: 
        url = lambda wildcards: config['URLs']['cDNA']
    shell:
        """
        wget -O {output}.gz {params.url}
        gunzip {output}.gz
        """

rule download_ensembl_genome:
    output: 
        "resources/genome/{spec}/genome.fa"
    params:
        url = lambda wildcards: config['URLs']['genome']
    shell:
        """
        wget -O {output}.gz {params.url}
        gunzip {output}.gz
        """
    
##--------------------------------------##
##  Make exon-intron annotation         ##
##--------------------------------------##

rule make_annot:
    input:
        gtf = "resources/genome/{spec}/gene_annotation.gtf"
    output:
        intron = "resources/genome/{spec}/ensembl.gtf.introns.final.bed",
        exon = "resources/genome/{spec}/ensembl.gtf.exons.final.bed",
        gene = "resources/genome/{spec}/ensembl.gtf.genes.final.bed"
    shell:
        """
        ml gcc/11.3.0 bedtools2
        bash scripts/Make_annot.sh {input.gtf} {output.intron} {output.exon} {output.gene}
        """

##-----------------------------------------------------------------##
##  Make pre-mRNA/mRNA annotation, kallisto index, kallisto quant  ##
##-----------------------------------------------------------------##

rule make_annot_kallisto:
    input:
        gtf = "resources/genome/{spec}/gene_annotation.gtf",
        cdna = "resources/genome/{spec}/cdna.fa",
        genome = "resources/genome/{spec}/genome.fa"
    output:
        cdna = "resources/genome/{spec}/cdna.kallisto.fa"
    shell:
        """
        ml gcc/11.3.0 bedtools2
        bash scripts/Make_annot_kallisto.sh {input.gtf} {input.cdna} {input.genome} {output.cdna}
        """

rule run_index_kallisto:
    input:
        cdna = "resources/genome/{spec}/cdna.kallisto.fa"
    output: 
        kal_index = "resources/genome/{spec}/transcripts.idx"
    shell:
        """
        ml gcc/11.3.0 kallisto
        kallisto index -i {output.kal_index} {input.cdna}
        """

rule kallisto_quant:
    input:
        index='resources/genome/{spec}/transcripts.idx'.format(spec=config['Species']),
        fq1='resources/{dataset}/fastq/{sample_name}_R1.fastq.gz',
        fq2='resources/{dataset}/fastq/{sample_name}_R2.fastq.gz'
    output:
        counts="results/{dataset}/kallisto/{sample_name}/abundance.tsv"
    params:
        dir=directory("results/{dataset}/kallisto/{sample_name}"),
        gtf='resources/genome/'+config['Species']+'/gene_annotation.gtf'
    threads: 72
    shell:
        """
        module load gcc/11.3.0 kallisto
        kallisto quant \
                 -i {input.index} \
                 --pseudobam \
                 --plaintext \
                 -b 50 \
                 -o {params.dir} \
                 -t {threads} \
                 {input.fq1} {input.fq2}
        """
                 #--genomebam \
                 #--gtf {params.gtf} \

rule make_tpm_tables:
    input:
        expand('results/{{dataset}}/kallisto/{sample_name}/abundance.tsv', sample_name=get_sample_name(config['Name']))
    output:
        premrna='results/{dataset}/kallisto/premrna_tpm_table.tab',
        mrna='results/{dataset}/kallisto/mrna_tpm_table.tab'
    shell:
        """
        python scripts/make_tpm_table.py --intables {input} --out_premrna {output.premrna} --out_mrna {output.mrna}
        """

rule make_promid_transcripts:
    input:
        promoterome=config['Promoterome']
    output:
        promid_transcripts="results/promoterome/{spec}/promid_transcripts.txt"
    shell:
        """
        ./scripts/make_promid_transcripts.sh {input.promoterome} {output.promid_transcripts}
        """

rule map_transcript_to_promoter:
    input:
        promid_transcripts="results/promoterome/{spec}/promid_transcripts.txt".format(spec=config['Species']),
        premrna="results/{dataset}/kallisto/premrna_tpm_table.tab",
        mrna="results/{dataset}/kallisto/mrna_tpm_table.tab"
    output:
        prom_premrna='results/{dataset}/kallisto/promoter_premrna_table.tab',
        prom_mrna='results/{dataset}/kallisto/promoter_mrna_table.tab'
    shell:
        """
        python scripts/get_transcript_to_promoter.py --promid_transcripts {input.promid_transcripts} --premrna {input.premrna} --mrna {input.mrna} --output_premrna {output.prom_premrna} --output_mrna {output.prom_mrna}
        """

##--------------------------------------------------------------##
##  Generate STAR genome index, align, index, make count table  ##
##--------------------------------------------------------------##

#rule star_genome_index:
#    input:
#        genome = "resources/genome/{spec}/genome.fa",
#        gtf = "resources/genome/{spec}/gene_annotation.gtf"
#    output:
#        genome_dir = directory("resources/genome/{spec}/star_index/")
#    params:
#        overhang = 100
#    threads: 24
#    shell:
#        """
#        module load gcc/11.3.0 star
#        mkdir -p {output.genome_dir}
#        STAR --runMode genomeGenerate \
#             --genomeDir {output.genome_dir} \
#             --genomeFastaFiles {input.genome} \
#             --sjdbGTFfile {input.gtf} \
#             --sjdbOverhang {params.overhang} \
#             --limitGenomeGenerateRAM 81000000000 \
#             --runThreadN {threads}
#        """
#
#rule star_align:
#    input:
#        fq1='resources/{dataset}/fastq/{sample}_1.fastq.gz',
#        fq2='resources/{dataset}/fastq/{sample}_2.fastq.gz',
#        gtf = "resources/genome/{spec}/gene_annotation.gtf",
#        genome_dir = "resources/genome/{spec}/star_index/"
#    output:
#        "results/star/{sample}/Aligned.sortedByCoord.out.bam"
#    params:
#        prefix="results/star/{sample}/",
#        outsamtype = "BAM SortedByCoordinate",
#        limitram = 81000000000
#    threads: 12
#    shell:
#        """
#        module load gcc/11.3.0 star
#        STAR --runMode alignReads \
#             --readFilesIn {input.fq1} {input.fq2} \
#             --genomeDir {input.genome_dir} \
#             --outFileNamePrefix {params.prefix} \
#             --outSAMtype {params.outsamtype} \
#             --limitBAMsortRAM {params.limitram} \
#             --sjdbGTFfile {input.gtf} \
#             --runThreadN {threads}
#        """
#
#rule sam_index:
#    input:
#        bam="results/star/{sample}/Aligned.sortedByCoord.out.bam"
#    output:
#        bam_index="results/star/{sample}/Aligned.sortedByCoord.out.bam.bai"
#    shell:
#        """
#        ml gcc/11.3.0 samtools
#        samtools index {input}
#        """
#
#rule countreads:
#    input:
#        bam = "results/star/{sample}/Aligned.sortedByCoord.out.bam",
#        bam_index = "results/star/{sample}/Aligned.sortedByCoord.out.bam.bai",
#        intron = "resources/genome/{spec}/ensembl.gtf.introns.final.bed".format(spec=config['Species']),
#        exon = "resources/genome/{spec}/ensembl.gtf.exons.final.bed".format(spec=config['Species'])
#    output:
#        "results/counting/{sample}/ie_ol.tsv"
#    shell:
#        """
#        ml gcc/11.3.0 samtools
#        perl scripts/Counting_IE_PairedEnd.pl {input.intron} {input.exon} {input.bam} > {output}
#        """
#
#rule merge_gene_counts:
#    input:
#        expand('results/star/{sample}_ReadsPerGene.out.tab', sample=get_acc_list(config['Name']))
#    output:
#        'results/star/GeneCount_table.tab'
#    shell:
#        """
#        outtable={output}
#        cut -f1 {input[0]} | tail -n+5 > $outtable
#        for i in {input}; do
#            paste $outtable <(cut -f2 $i | tail -n+5) > tmp.txt
#            mv tmp.txt $outtable
#        done
#        """
#
#rule merged_transcriptome:
#    input:
#        expand('results/star/{sample}_Aligned.toTranscriptome.out.bam', sample=get_acc_list(config['Name']))
#    output:
#        'results/star/merged_transcriptome.bam'
#    shell:
#        """
#        samtools sort -@ 12 -o {output} {input}
#        samtools index {output}
#        """
#

